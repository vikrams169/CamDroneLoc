{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from os import walk\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_img1 = cv2.imread(\"satellite_imgs/related_img1.png\")\n",
    "related_img2 = cv2.imread(\"satellite_imgs/related_img2.png\")\n",
    "unrelated_img = cv2.imread(\"satellite_imgs/unrelated_img.png\")\n",
    "\n",
    "sfo1 = cv2.imread(\"satellite_imgs/sfo1.png\")\n",
    "sfo2 = cv2.imread(\"satellite_imgs/sfo2.png\")\n",
    "sfo1_rot = cv2.imread(\"satellite_imgs/sfo1_rotated.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VecKMEncoder:\n",
    "    def __init__(self):\n",
    "        self.d = 1024\n",
    "        self.alpha = 0.1\n",
    "        self.W = np.stack([self.strict_standard_normal(self.d) for _ in range(2)], axis=0) * self.alpha\n",
    "        self.detector = cv2.SIFT_create(1000)\n",
    "        \n",
    "    def strict_standard_normal(self, d):\n",
    "        y = np.linspace(0, 1, d+2)\n",
    "        x = norm.ppf(y)[1:-1]\n",
    "        np.random.shuffle(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, img):\n",
    "        kp = self.detector.detect(img, None)\n",
    "        pts = cv2.KeyPoint_convert(kp).astype(np.complex128)\n",
    "        Z = np.exp(1j * pts @ self.W).sum(axis=0)\n",
    "        Z = Z / np.linalg.norm(Z)\n",
    "        return Z\n",
    "\n",
    "    def similarity(self, x, y):\n",
    "        return np.absolute(np.sum(x * y.conj()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLCosineEncoder:\n",
    "    def __init__(self):\n",
    "        # Load the pretrained model\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        # Use the model object to select the desired layer\n",
    "        self.layer = self.model._modules.get('avgpool')\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        self.model.eval()\n",
    "        self.scaler = transforms.Resize((224, 224))\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.sift_function = cv2.SIFT_create(nfeatures=500)\n",
    "        self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    def get_kpt_img(self, rgb_img):\n",
    "        gray_img = cv2.cvtColor(rgb_img,cv2.COLOR_BGR2GRAY) # Converting the RGB image to grayscale\n",
    "         # Creating an instance of the SIFT Function\n",
    "        keypoints, features = self.sift_function.detectAndCompute(gray_img,None) # Computing the set of keypoints and features for the image\n",
    "        blank = np.zeros(rgb_img.shape).astype(np.uint8)\n",
    "        for i in range(len(keypoints)):\n",
    "    #         print(int(keypoints[i].pt[1]),int(keypoints[i].pt[0]))\n",
    "            cv2.circle(blank, (int(keypoints[i].pt[0]),int(keypoints[i].pt[1])), 3, (255,255,255), -1)\n",
    "    #         blank[int(keypoints[i].pt[1]),int(keypoints[i].pt[0])] = [255,255,255]\n",
    "        return blank\n",
    "    \n",
    "    def get_vector(self, img):\n",
    "        # 2. Create a PyTorch Variable with the transformed image\n",
    "        t_img = Variable(self.normalize(self.scaler(self.to_tensor(img))).unsqueeze(0))\n",
    "        # 3. Create a vector of zeros that will hold our feature vector\n",
    "        #    The 'avgpool' layer has an output size of 512\n",
    "        my_embedding = torch.zeros(1,512,1,1)\n",
    "        # 4. Define a function that will copy the output of a layer\n",
    "\n",
    "        def copy_data(m, i, o):\n",
    "            my_embedding.copy_(o.data)\n",
    "        # 5. Attach that function to our selected layer\n",
    "        h = self.layer.register_forward_hook(copy_data)\n",
    "        # 6. Run the model on our transformed image\n",
    "        self.model(t_img)\n",
    "        # 7. Detach our copy function from the layer\n",
    "        h.remove()\n",
    "        # 8. Return the feature vector\n",
    "        return my_embedding\n",
    "    \n",
    "    def similarity(self, x, y):\n",
    "        return self.cos(x.unsqueeze(0),y.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HistEncoder():\n",
    "\n",
    "    def __init__(self,siftD=128,num_clusters=64):\n",
    "        self.siftD = siftD\n",
    "        self.num_clusters = num_clusters\n",
    "        self.clustering_model = self.create_hist_model()\n",
    "\n",
    "    def detect_sift_features(self,rgb_img):\n",
    "        gray_img = cv2.cvtColor(rgb_img,cv2.COLOR_BGR2GRAY)\n",
    "        sift_function = cv2.SIFT_create(nfeatures=128)\n",
    "        keypoints, features = sift_function.detectAndCompute(gray_img,None)\n",
    "        return keypoints, features\n",
    "\n",
    "    def create_hist_model(self):\n",
    "        all_features = []\n",
    "        filenames = next(walk(\"./satellite_imgs/\"), (None, None, []))[2]  # [] if no file\n",
    "        for image_path in filenames:\n",
    "            img = cv2.imread(\"./satellite_imgs/\" + image_path)\n",
    "            keypoints, features = self.detect_sift_features(img)\n",
    "            all_features.append(features)\n",
    "        features_array = np.concatenate(all_features,axis=0).reshape((-1,self.siftD))\n",
    "        clustering_model = KMeans(n_clusters=64,n_init=\"auto\")\n",
    "        clustering_model.fit(features_array)\n",
    "        return clustering_model\n",
    "\n",
    "    def hist_encode(self,rgb_img):\n",
    "        keypoints, features = self.detect_sift_features(rgb_img)\n",
    "        features = np.array(features).reshape((-1,self.siftD))\n",
    "        feature_labels = self.clustering_model.predict(features).reshape((-1))\n",
    "        hist, bin_edges = np.histogram(feature_labels,bins=[i for i in range(self.num_clusters)])\n",
    "        return np.array(hist).astype(np.float32)\n",
    "\n",
    "    def hist_similarity_correlation(self,hist1,hist2):\n",
    "        sim = cv2.compareHist(hist1,hist2,0)\n",
    "        return sim\n",
    "\n",
    "    def hist_similarity_intersection(self,hist1,hist2):\n",
    "        sim = cv2.compareHist(hist1,hist2,2)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DLCos = DLCosineEncoder()\n",
    "\n",
    "vec1 = DLCos.get_vector(related_img1)\n",
    "vec1_resize = vec1.view(512)\n",
    "vec2 = DLCos.get_vector(related_img2)\n",
    "vec2_resize = vec2.view(512)\n",
    "vec3 = DLCos.get_vector(unrelated_img)\n",
    "vec3_resize = vec3.view(512)\n",
    "sfo_vec1 = DLCos.get_vector(sfo1)\n",
    "sfo_vec1_resize = sfo_vec1.view(512)\n",
    "sfo_vec2 = DLCos.get_vector(sfo2)\n",
    "sfo_vec2_resize = sfo_vec2.view(512)\n",
    "sfo_vec3 = DLCos.get_vector(sfo1_rot)\n",
    "sfo_vec3_resize = sfo_vec3.view(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim1_2 = DLCos.similarity(vec1_resize, vec2_resize)\n",
    "cos_sim2_3 = DLCos.similarity(vec2_resize, vec3_resize)\n",
    "cos_sim1_3 = DLCos.similarity(vec1_resize, vec3_resize)\n",
    "\n",
    "sfo_cos_sim1_2 = DLCos.similarity(sfo_vec1_resize, sfo_vec2_resize)\n",
    "sfo_cos_sim2_3 = DLCos.similarity(sfo_vec2_resize, sfo_vec3_resize)\n",
    "sfo_cos_sim1_3 = DLCos.similarity(sfo_vec1_resize, sfo_vec3_resize)\n",
    "\n",
    "cos_1_sfo = DLCos.similarity(vec1_resize, sfo_vec3_resize)\n",
    "\n",
    "print(cos_sim1_2, cos_sim2_3, cos_sim1_3, sfo_cos_sim1_2, sfo_cos_sim2_3, sfo_cos_sim1_3, cos_1_sfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VecKM = VecKMEncoder()\n",
    "\n",
    "vec1 = VecKM.encode(related_img1)\n",
    "vec2 = VecKM.encode(related_img2)\n",
    "vec3 = VecKM.encode(unrelated_img)\n",
    "\n",
    "sfo_vec1 = VecKM.encode(sfo1)\n",
    "sfo_vec2 = VecKM.encode(sfo2)\n",
    "sfo_vec3 = VecKM.encode(sfo1_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_2 = VecKM.similarity(vec1, vec2)\n",
    "sim2_3 = VecKM.similarity(vec2, vec3)\n",
    "sim1_3 = VecKM.similarity(vec1, vec3)\n",
    "\n",
    "sfo_sim1_2 = VecKM.similarity(sfo_vec1, sfo_vec2)\n",
    "sfo_sim2_3 = VecKM.similarity(sfo_vec2, sfo_vec3)\n",
    "sfo_sim1_3 = VecKM.similarity(sfo_vec1, sfo_vec3)\n",
    "\n",
    "one_sfo = VecKM.similarity(vec1, sfo_vec3)\n",
    "\n",
    "print(sim1_2, sim2_3, sim1_3, sfo_sim1_2, sfo_sim2_3, sfo_sim1_3, one_sfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "HistE = HistEncoder()\n",
    "\n",
    "vec1 = HistE.hist_encode(related_img1)\n",
    "vec2 = HistE.hist_encode(related_img2)\n",
    "vec3 = HistE.hist_encode(unrelated_img)\n",
    "\n",
    "sfo_vec1 = HistE.hist_encode(sfo1)\n",
    "sfo_vec2 = HistE.hist_encode(sfo2)\n",
    "sfo_vec3 = HistE.hist_encode(sfo1_rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_2 = HistE.hist_similarity_correlation(vec1, vec2)\n",
    "sim2_3 = HistE.hist_similarity_correlation(vec2, vec3)\n",
    "sim1_3 = HistE.hist_similarity_correlation(vec1, vec3)\n",
    "\n",
    "sfo_sim1_2 = HistE.hist_similarity_correlation(sfo_vec1, sfo_vec2)\n",
    "sfo_sim2_3 = HistE.hist_similarity_correlation(sfo_vec2, sfo_vec3)\n",
    "sfo_sim1_3 = HistE.hist_similarity_correlation(sfo_vec1, sfo_vec3)\n",
    "\n",
    "one_sfo = HistE.hist_similarity_correlation(vec1, sfo_vec3)\n",
    "\n",
    "print(sim1_2, sim2_3, sim1_3, sfo_sim1_2, sfo_sim2_3, sfo_sim1_3, one_sfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1_2 = HistE.hist_similarity_intersection(vec1, vec2)\n",
    "sim2_3 = HistE.hist_similarity_intersection(vec2, vec3)\n",
    "sim1_3 = HistE.hist_similarity_intersection(vec1, vec3)\n",
    "\n",
    "sfo_sim1_2 = HistE.hist_similarity_intersection(sfo_vec1, sfo_vec2)\n",
    "sfo_sim2_3 = HistE.hist_similarity_intersection(sfo_vec2, sfo_vec3)\n",
    "sfo_sim1_3 = HistE.hist_similarity_intersection(sfo_vec1, sfo_vec3)\n",
    "\n",
    "one_sfo = HistE.hist_similarity_intersection(vec1, sfo_vec3)\n",
    "\n",
    "print(sim1_2, sim2_3, sim1_3, sfo_sim1_2, sfo_sim2_3, sfo_sim1_3, one_sfo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
